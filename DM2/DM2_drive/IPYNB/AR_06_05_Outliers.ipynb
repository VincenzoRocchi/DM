{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing Dataset\n",
    "df_train = pd.read_csv(\"TRAIN_PREPROCESED_DT.csv\")\n",
    "df_test = pd.read_csv(\"TEST_PREPROCESED_DT.csv\")\n",
    "\n",
    "df_train_KNN = pd.read_csv(\"TRAIN_PREPROCESED_KNN.csv\")\n",
    "df_test_KNN = pd.read_csv(\"TEST_PREPROCESED_KNN.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'emotional_intensity'\n",
    "\n",
    "attributes = [col for col in df_train.columns if col != target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[attributes]\n",
    "y_train = df_train[target_name]\n",
    "X_test = df_test[attributes]\n",
    "y_test = df_test[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking performance of classification Before outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Performance BEFORE removing outliers:\n",
      "Accuracy 0.7308533916849015\n",
      "F1-score [0.73202614 0.72967033]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.73       245\n",
      "           1       0.68      0.78      0.73       212\n",
      "\n",
      "    accuracy                           0.73       457\n",
      "   macro avg       0.73      0.73      0.73       457\n",
      "weighted avg       0.74      0.73      0.73       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking performance of classification Before outlier removal\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Create a decision tree classifier object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Use the best estimator to make predictions on the test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_val)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print('Decision Tree Classifier Performance BEFORE removing outliers:')\n",
    "print('Accuracy %s' % accuracy_score(y_val, y_pred))\n",
    "print('F1-score %s' % f1_score(y_val, y_pred, average=None))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Finding the best K and T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k = 20 , Best T = 5\n",
      "Accuracy: 0.7067307692307693\n",
      "F1 Score: 0.7071046377075165\n"
     ]
    }
   ],
   "source": [
    "# Finding the best K and T\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# define a range of values for k and T\n",
    "k_values = [5, 10, 15, 20]\n",
    "T_values = [2, 5, 8, 10]\n",
    "\n",
    "# initialize variables to store the best hyperparameters and performance\n",
    "max_f1_score = 0\n",
    "max_accuracy = 0\n",
    "best_k = None\n",
    "best_T = None\n",
    "\n",
    "# iterate over all possible combinations of k and T\n",
    "for k in k_values:\n",
    "    for T in T_values:\n",
    "        \n",
    "        # calculate the in-degree of each vertex in the kNN graph\n",
    "        n = X_train.shape[0] # number of vertices in graph\n",
    "        graph = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            distances = np.linalg.norm(X_train - X_train.iloc[i], axis=1)\n",
    "            neighbors = np.argsort(distances)[1:k+1] # exclude self as nearest neighbor\n",
    "            for j in neighbors:\n",
    "                graph[i][j] = 1 # add directed edge from i to j\n",
    "        in_degree = np.sum(graph, axis=0)\n",
    "\n",
    "        # detect outliers based on in-degree threshold\n",
    "        outliers = np.where(in_degree <= T)[0]\n",
    "        inliers = np.where(in_degree > T)[0]\n",
    "\n",
    "        # remove the outliers from the training set\n",
    "        X_train_filtered = X_train.iloc[inliers]\n",
    "        y_train_filtered = y_train.iloc[inliers]\n",
    "\n",
    "        # train a decision tree classifier\n",
    "        dtc = DecisionTreeClassifier(random_state=42)\n",
    "        dtc.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "        # make predictions on the test set\n",
    "        y_pred = dtc.predict(X_val)\n",
    "\n",
    "        # evaluate the performance of the decision tree classifier\n",
    "        f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        # print('k =', k, ', T =', T)\n",
    "        # print('Accuracy:', acc)\n",
    "        # print('F1 Score:', f1)\n",
    "        # print(classification_report(y_test, y_pred)) \n",
    "        \n",
    "        # update max_f1_score and max_accuracy if current values are higher\n",
    "        if f1 > max_f1_score and acc > max_accuracy:\n",
    "            max_f1_score = f1\n",
    "            max_accuracy = acc\n",
    "            best_k = k\n",
    "            best_T = T\n",
    "            \n",
    "print('Best k =', best_k, ', Best T =', best_T)\n",
    "print('Accuracy:', max_accuracy)\n",
    "print('F1 Score:', max_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train before removing outliers: (1371, 386)\n",
      "Shape of X_val before removing outliers: (457, 386)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the found values for K=20 and T=5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# print the shape of the dataset before removing outliers\n",
    "print('Shape of X_train before removing outliers:', X_train.shape)\n",
    "print('Shape of y_train before removing outliers:', y_train.shape)\n",
    "\n",
    "# calculate the in-degree of each vertex in the kNN graph\n",
    "k = 20 # number of neighbors for kNN graph\n",
    "T = 5 # in-degree threshold for outlier detection\n",
    "n = X_train.shape[0] # number of vertices in graph\n",
    "graph = np.zeros((n, n))\n",
    "for i in range(n):\n",
    "    distances = np.linalg.norm(X_train - X_train.iloc[i], axis=1)\n",
    "    neighbors = np.argsort(distances)[1:k+1] # exclude self as nearest neighbor\n",
    "    for j in neighbors:\n",
    "        graph[i][j] = 1 # add directed edge from i to j\n",
    "in_degree = np.sum(graph, axis=0)\n",
    "\n",
    "# detect outliers based on in-degree threshold\n",
    "outliers = np.where(in_degree <= T)[0]\n",
    "inliers = np.where(in_degree > T)[0]\n",
    "\n",
    "# remove the outliers from the training set\n",
    "X_train_rem = X_train.iloc[inliers]\n",
    "y_train_rem = y_train.iloc[inliers]\n",
    "\n",
    "# train a decision tree classifier\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(X_train_rem, y_train_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train after removing outliers: (1279, 386)\n",
      "Shape of y_train after removing outliers: (1279,)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of the dataset before removing outliers\n",
    "print('Shape of X_train after removing outliers:', X_train_rem.shape)\n",
    "print('Shape of y_train after removing outliers:', y_train_rem.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Checking performance of classification fter outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Performance AFTER removing outliers:\n",
      "Accuracy 0.7133479212253829\n",
      "F1-score [0.77452668 0.60660661]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.92      0.77       245\n",
      "           1       0.83      0.48      0.61       212\n",
      "\n",
      "    accuracy                           0.71       457\n",
      "   macro avg       0.75      0.70      0.69       457\n",
      "weighted avg       0.75      0.71      0.70       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking performance of classification fter outlier removal\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Create a decision tree classifier object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(X_train_rem, y_train_rem)\n",
    "\n",
    "# Use the best estimator to make predictions on the test set\n",
    "y_pred = grid_search.best_estimator_.predict(X_val)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print('Decision Tree Classifier Performance AFTER removing outliers:')\n",
    "print('Accuracy %s' % accuracy_score(y_val, y_pred))\n",
    "print('F1-score %s' % f1_score(y_val, y_pred, average=None))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier Performance AFTER removing outliers: with X_val\n",
    "# Accuracy 0.7155361050328227\n",
    "# F1-score [0.77430556 0.61538462]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.67      0.91      0.77       245\n",
    "#          1.0       0.83      0.49      0.62       212\n",
    "\n",
    "#     accuracy                           0.72       457\n",
    "#    macro avg       0.75      0.70      0.69       457\n",
    "# weighted avg       0.74      0.72      0.70       457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier Performance AFTER removing outliers: with X_test\n",
    "# Accuracy 0.5384615384615384\n",
    "# F1-score [0.7 0. ]\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.54      1.00      0.70       336\n",
    "#            1       0.00      0.00      0.00       288\n",
    "\n",
    "#     accuracy                           0.54       624\n",
    "#    macro avg       0.27      0.50      0.35       624\n",
    "# weighted avg       0.29      0.54      0.38       624\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'emotional_intensity'\n",
    "\n",
    "attributes = [col for col in df_train_KNN.columns if col != target_name]\n",
    "\n",
    "X_train_KNN = df_train_KNN[attributes]\n",
    "y_train_KNN = df_train_KNN[target_name]\n",
    "X_test_KNN = df_test_KNN[attributes]\n",
    "y_test_KNN = df_test_KNN[target_name]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_KNN, X_val_KNN, y_train_KNN, y_val_KNN = train_test_split(X_train_KNN, y_train_KNN, test_size=0.25, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking performance of classification Before outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Classifier Performance BEFORE removing outliers:\n",
      "Accuracy 0.7636761487964989\n",
      "F1-score [0.78740157 0.73399015]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       245\n",
      "           1       0.77      0.70      0.73       212\n",
      "\n",
      "    accuracy                           0.76       457\n",
      "   macro avg       0.76      0.76      0.76       457\n",
      "weighted avg       0.76      0.76      0.76       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Create a k-NN classifier object\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(X_train_KNN, y_train_KNN)\n",
    "\n",
    "# Use the best estimator to make predictions on the test set\n",
    "y_pred_KNN = grid_search.best_estimator_.predict(X_val_KNN)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print('k-NN Classifier Performance BEFORE removing outliers:')\n",
    "print('Accuracy %s' % accuracy_score(y_val_KNN, y_pred_KNN))\n",
    "print('F1-score %s' % f1_score(y_val_KNN, y_pred_KNN, average=None))\n",
    "print(classification_report(y_val_KNN, y_pred_KNN))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best K and T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k_KNN = 15 , Best T_KNN = 5\n",
      "Accuracy_KNN: 0.7549234135667396\n",
      "F1 Score_KNN: 0.7488443120637964\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# define a range of values for k and T\n",
    "k_values = [5, 10, 15, 20]\n",
    "T_values = [2, 5, 8, 10]\n",
    "\n",
    "# initialize variables to store the best hyperparameters and performance\n",
    "max_f1_score_KNN = 0\n",
    "max_accuracy_KNN = 0\n",
    "best_k_KNN = None\n",
    "best_T_KNN = None\n",
    "\n",
    "# iterate over all possible combinations of k and T\n",
    "for k in k_values:\n",
    "    for T in T_values:\n",
    "        \n",
    "        # calculate the in-degree of each vertex in the kNN graph\n",
    "        n = X_train_KNN.shape[0] # number of vertices in graph\n",
    "        graph = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            distances = np.linalg.norm(X_train_KNN - X_train_KNN.iloc[i], axis=1)\n",
    "            neighbors = np.argsort(distances)[1:k+1] # exclude self as nearest neighbor\n",
    "            for j in neighbors:\n",
    "                graph[i][j] = 1 # add directed edge from i to j\n",
    "        in_degree = np.sum(graph, axis=0)\n",
    "\n",
    "        # detect outliers based on in-degree threshold\n",
    "        outliers = np.where(in_degree <= T)[0]\n",
    "        inliers = np.where(in_degree > T)[0]\n",
    "\n",
    "        # remove the outliers from the training set\n",
    "        X_train_filtered_KNN = X_train_KNN.iloc[inliers]\n",
    "        y_train_filtered_KNN = y_train_KNN.iloc[inliers]\n",
    "\n",
    "        # train a KNN classifier\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train_filtered_KNN, y_train_filtered_KNN)\n",
    "\n",
    "        # make predictions on the validation set\n",
    "        y_pred_KNN = knn.predict(X_val_KNN)\n",
    "\n",
    "        # evaluate the performance of the KNN classifier\n",
    "        f1_KNN = f1_score(y_val_KNN, y_pred_KNN, average='weighted')\n",
    "        acc_KNN = accuracy_score(y_val_KNN, y_pred_KNN)\n",
    "        \n",
    "        # update max_f1_score_KNN and max_accuracy_KNN if current values are higher\n",
    "        if f1_KNN > max_f1_score_KNN and acc_KNN > max_accuracy_KNN:\n",
    "            max_f1_score_KNN = f1_KNN\n",
    "            max_accuracy_KNN = acc_KNN\n",
    "            best_k_KNN = k\n",
    "            best_T_KNN = T\n",
    "            \n",
    "print('Best k_KNN =', best_k_KNN, ', Best T_KNN =', best_T_KNN)\n",
    "print('Accuracy_KNN:', max_accuracy_KNN)\n",
    "print('F1 Score_KNN:', max_f1_score_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train before removing outliers: (1371, 50)\n",
      "Shape of y_train before removing outliers: (1371,)\n"
     ]
    }
   ],
   "source": [
    "# Using the found values for K=20 and T=5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# print the shape of the dataset before removing outliers\n",
    "print('Shape of X_train before removing outliers:', X_train_KNN.shape)\n",
    "print('Shape of y_train before removing outliers:', y_train_KNN.shape)\n",
    "\n",
    "# calculate the in-degree of each vertex in the kNN graph\n",
    "k = 15 # number of neighbors for kNN graph\n",
    "T = 5 # in-degree threshold for outlier detection\n",
    "\n",
    "n = X_train_KNN.shape[0] # number of vertices in graph\n",
    "graph = np.zeros((n, n))\n",
    "for i in range(n):\n",
    "    distances = np.linalg.norm(X_train_KNN - X_train_KNN.iloc[i], axis=1)\n",
    "    neighbors = np.argsort(distances)[1:k+1] # exclude self as nearest neighbor\n",
    "    for j in neighbors:\n",
    "        graph[i][j] = 1 # add directed edge from i to j\n",
    "in_degree = np.sum(graph, axis=0)\n",
    "\n",
    "# detect outliers based on in-degree threshold\n",
    "outliers = np.where(in_degree <= T)[0]\n",
    "inliers = np.where(in_degree > T)[0]\n",
    "\n",
    "# remove the outliers from the training set\n",
    "X_train_rem_KNN = X_train_KNN.iloc[inliers]\n",
    "y_train_rem_KNN = y_train_KNN.iloc[inliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train after removing outliers: (1205, 50)\n",
      "Shape of y_train after removing outliers: (1205,)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of the dataset before removing outliers\n",
    "print('Shape of X_train after removing outliers:', X_train_rem_KNN.shape)\n",
    "print('Shape of y_train after removing outliers:', y_train_rem_KNN.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking permformance of Outliers removal Algo AFTER REMOVAL using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Performance AFTER removing outliers:\n",
      "Accuracy 0.7636761487964989\n",
      "F1-score [0.79545455 0.72020725]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80       245\n",
      "           1       0.80      0.66      0.72       212\n",
      "\n",
      "    accuracy                           0.76       457\n",
      "   macro avg       0.77      0.76      0.76       457\n",
      "weighted avg       0.77      0.76      0.76       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Create a KNN classifier object\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(X_train_rem_KNN, y_train_rem_KNN)\n",
    "\n",
    "# Use the best estimator to make predictions on the test set\n",
    "y_pred_KNN = grid_search.best_estimator_.predict(X_val_KNN)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print('Decision Tree Classifier Performance AFTER removing outliers:')\n",
    "print('Accuracy %s' % accuracy_score(y_val_KNN, y_pred_KNN))\n",
    "print('F1-score %s' % f1_score(y_val_KNN, y_pred_KNN, average=None))\n",
    "print(classification_report(y_val_KNN, y_pred_KNN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
